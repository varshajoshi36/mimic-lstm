{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#3/13/18\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def OH_F(ITID, items_l):\n",
    "        oh_v = np.zeros(len(items_l))\n",
    "        iidx = 0\n",
    "        for item in items_l:\n",
    "            if ITID == item:\n",
    "                oh_v[iidx] = 1\n",
    "            iidx += 1\n",
    "        return (pd.DataFrame(oh_v))\n",
    "    \n",
    "def myGenerator_tr():\n",
    "    ##Yields tuple for rows of chartevents csv file for a single HADM_ID each time it is called. Tuple contains HADM_ID and 3 Nx1 np.arrays for item id chartime and valuenum respectively  \n",
    "    #(Assumes csv is sort by HADM_ID)\n",
    "    a_df = pd.read_csv('/soe/dcjenkin/mimic3/mimic3/ADMISSIONS.csv')\n",
    "    chart_path = '/soe/dcjenkin/mimic3/mimic3/CHARTEVENTS_tr.csv'\n",
    "    item_list = [220045,211,51,8368,807,227037,223761,227059,220277,220210,198,223835,1817]\n",
    "    ADM_DTH_Dict = {}\n",
    "    \n",
    "    for i, row in a_df.iterrows():\n",
    "        ADM_DTH_Dict[row['HADM_ID']] = [row['ADMITTIME'], row['DISCHTIME'], row['DEATHTIME']]\n",
    "    first_bool = True\n",
    "    \n",
    "    for df in pd.read_csv(chart_path ,sep=',', chunksize=1, usecols=['HADM_ID', 'ITEMID', 'CHARTTIME', 'VALUENUM']):\n",
    "        #Loop through csv line by line appending to HADM_ID_chunk.\n",
    "        if df.iloc[0,1] in item_list: #IF ITID is in item_IDs list\n",
    "            if not pd.isnull(df.iloc[0,3]): #If the valuenum is not null\n",
    "                OH_V = OH_F(df.iloc[0,1], item_list)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                df = pd.concat([df, OH_V.T], axis = 1)\n",
    "                if first_bool:\n",
    "                    last_row_HADM_ID = df.iloc[0,0] #HADM_ID\n",
    "                    first_bool = False\n",
    "                    HADM_ID_chunk = df\n",
    "                else:\n",
    "                    next_row_HADM_ID = df.iloc[0,0]\n",
    "                    #When HADM_ID changes, yield HADM_ID_chunk as np array then start new chunk.\n",
    "                    if next_row_HADM_ID == last_row_HADM_ID:\n",
    "                        HADM_ID_chunk = HADM_ID_chunk.append(df)\n",
    "                    else:\n",
    "                        chunk_array = np.array(HADM_ID_chunk)\n",
    "                        ADM_DTH_array = np.array(ADM_DTH_Dict[last_row_HADM_ID])\n",
    "                        \n",
    "                        if pd.isnull(ADM_DTH_array[2]):\n",
    "                            H_Mortality = 0\n",
    "                        else: \n",
    "                            H_Mortality = int(pd.Timestamp(ADM_DTH_array[2]) <= pd.Timestamp(ADM_DTH_array[1]))\n",
    "                            \n",
    "                        yield (chunk_array[0,0], chunk_array[:,1] ,chunk_array[:,2], chunk_array[:,3:], ADM_DTH_array, H_Mortality)\n",
    "                        HADM_ID_chunk = df\n",
    "                    last_row_HADM_ID = next_row_HADM_ID\n",
    "                    \n",
    "\n",
    "def myGenerator_test():\n",
    "    ##Yields tuple for rows of chartevents csv file for a single HADM_ID each time it is called. Tuple contains HADM_ID and 3 Nx1 np.arrays for item id chartime and valuenum respectively  \n",
    "    #(Assumes csv is sort by HADM_ID)\n",
    "    a_df = pd.read_csv('/soe/dcjenkin/mimic3/mimic3/ADMISSIONS.csv')\n",
    "    chart_path = '/soe/dcjenkin/mimic3/mimic3/CHARTEVENTS_test.csv'\n",
    "    item_list = [220045,211,51,8368,807,227037,223761,227059,220277,220210,198,223835,1817]\n",
    "    ADM_DTH_Dict = {}\n",
    "    \n",
    "    for i, row in a_df.iterrows():\n",
    "        ADM_DTH_Dict[row['HADM_ID']] = [row['ADMITTIME'], row['DISCHTIME'], row['DEATHTIME']]\n",
    "    first_bool = True\n",
    "    \n",
    "    for df in pd.read_csv(chart_path ,sep=',', chunksize=1, usecols=['HADM_ID', 'ITEMID', 'CHARTTIME', 'VALUENUM']):\n",
    "        #Loop through csv line by line appending to HADM_ID_chunk.\n",
    "        if df.iloc[0,1] in item_list: #IF ITID is in item_IDs list\n",
    "            if not pd.isnull(df.iloc[0,3]): #If the valuenum is not null\n",
    "                OH_V = OH_F(df.iloc[0,1], item_list)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                df = pd.concat([df, OH_V.T], axis = 1)\n",
    "                if first_bool:\n",
    "                    last_row_HADM_ID = df.iloc[0,0] #HADM_ID\n",
    "                    first_bool = False\n",
    "                    HADM_ID_chunk = df\n",
    "                else:\n",
    "                    next_row_HADM_ID = df.iloc[0,0]\n",
    "                    #When HADM_ID changes, yield HADM_ID_chunk as np array then start new chunk.\n",
    "                    if next_row_HADM_ID == last_row_HADM_ID:\n",
    "                        HADM_ID_chunk = HADM_ID_chunk.append(df)\n",
    "                    else:\n",
    "                        chunk_array = np.array(HADM_ID_chunk)\n",
    "                        ADM_DTH_array = np.array(ADM_DTH_Dict[last_row_HADM_ID])\n",
    "                        \n",
    "                        if pd.isnull(ADM_DTH_array[2]):\n",
    "                            H_Mortality = 0\n",
    "                        else: \n",
    "                            H_Mortality = int(pd.Timestamp(ADM_DTH_array[2]) <= pd.Timestamp(ADM_DTH_array[1]))\n",
    "                            \n",
    "                        yield (chunk_array[0,0], chunk_array[:,1] ,chunk_array[:,2], chunk_array[:,3:], ADM_DTH_array, H_Mortality)\n",
    "                        HADM_ID_chunk = df\n",
    "                    last_row_HADM_ID = next_row_HADM_ID\n",
    "                    \n",
    "def map_func1(HADM_ID, ITEM_IDs, Charttimes, Values, ADM_DSC_DTH, H_Mort):\n",
    "    num_meas = tf.shape(Values)[0]\n",
    "    #finds the number of groups.  Each group contains n_steps = 100 measurements per patient\n",
    "    #(eg if there are 637 measurements for a patient that would form 7 groups).\n",
    "    numgroup_minus_one = tf.reduce_max([tf.to_int32(tf.ceil(num_meas/100))-1, 0])\n",
    "    #generates labels for each group indicating mortality at the end of that group.  Only the final group can be non-zero as the patients are still alive if measurements are still being taken.\n",
    "    labellist = tf.zeros([numgroup_minus_one], tf.int32)\n",
    "    labellist = tf.concat([labellist, [H_Mort]], 0)\n",
    "    \n",
    "    paddings = tf.constant([[0, 100,], [0, 0]])\n",
    "    Values = tf.pad(Values, paddings, \"CONSTANT\")\n",
    "    return HADM_ID, ITEM_IDs, Charttimes, Values, ADM_DSC_DTH, H_Mort, labellist, num_meas\n",
    "\n",
    "def map_func2(HADM_ID, ITEM_IDs, Charttimes, Values, ADM_DSC_DTH, H_Mort, labellist, num_meas):\n",
    "    #find the max number of measurements for patients in the batch.\n",
    "    mlen = tf.reduce_max(num_meas)\n",
    "    #round up to nearest 100 and take only the values up to this index.  (All values after rmlen should be zeros from the padding)\n",
    "    rmlen = tf.to_int32(tf.ceil(mlen/100)*100)\n",
    "    Values = Values[:,0:rmlen]\n",
    "    #split up into groups of 100 measurements each\n",
    "    Values = tf.reshape(Values, [2,-1,100,14])\n",
    "    #transpose to match format for rnn.\n",
    "    Values = tf.transpose(Values, perm=[1, 0, 2, 3]) #(number of groups, batch size, n_steps, number of feature types)\n",
    "    labellist = tf.transpose(labellist, perm=[1,0])\n",
    "\n",
    "    return HADM_ID, ITEM_IDs, Charttimes, Values, ADM_DSC_DTH, H_Mort, labellist, num_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f03be47f828>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soe/dcjenkin/workspace/venv/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_input = 14   # (OH encoded vector of length 13, value)\n",
    "\n",
    "n_steps = 100  #100 timesteps per batch\n",
    "\n",
    "n_hidden = 100  # hidden layer num of features\n",
    "\n",
    "n_classes = 1  # Mortality in hospital.  The network will put out one value between 0 and 1 at each timestep indicating the prediction whether the patient has lived or died.  (0 for lived, 1 for died)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# X_lengths = tf.placeholder(tf.int32, [None], name='X_lengths')  #feed in the unpadded sequence length for each batch\n",
    "\n",
    "# tf Graph input (X is a 3D array of inuts (number of patients x number of measurements x 14 for OH vector and value))\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_input], name='X')\n",
    "# y is a 1D array of labels shape = (number of patients). Here for a given patient the label is the same at each time step since it just indicates whether that patient died in the hospital.\n",
    "y = tf.placeholder(tf.float32, [None], name='y')\n",
    "y2 = tf.reshape(y, shape = (batch_size,-1))\n",
    "\n",
    "#Weights and Biases to map hidden state to n_classes predictions\n",
    "w1 = tf.Variable(tf.random_normal([n_hidden, n_classes]), name='w1')\n",
    "b1 = tf.Variable(tf.random_normal([n_classes]), name='w2')\n",
    "\n",
    "\n",
    "def length(sequence):\n",
    "    #returns a vector of sequence lengths for each patient within the batch segment\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "\n",
    "X_l = length(X)\n",
    "\n",
    "# Define a lstm cell with tensorflow\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=False)\n",
    "\n",
    "state = tf.Variable(lstm_cell.zero_state(batch_size, tf.float32), trainable=False)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "        cell=lstm_cell,\n",
    "        dtype=tf.float32,\n",
    "        sequence_length=X_l,\n",
    "        inputs=X,\n",
    "        initial_state=state)\n",
    "\n",
    "state_op = tf.assign(state, states)\n",
    "\n",
    "\n",
    "def last_relevant(output, length):\n",
    "    #returns outputs for each patient at the indexes given in length\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "    return relevant\n",
    "\n",
    "\n",
    "# Remove patients from batch that have no measurements for that batch (ie the length of the sequence is zero for that patient for that batch).\n",
    "# mask = np.array([False, True])\n",
    "mask = X_l > 0\n",
    "outputs2 = tf.boolean_mask(outputs, mask)\n",
    "X_l2 = tf.boolean_mask(X_l, mask)\n",
    "y3 = tf.boolean_mask(y2, mask)\n",
    "masksum = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "\n",
    "# outputs2 = outputs[1]\n",
    "# X_l \n",
    "\n",
    "rel = last_relevant(outputs2, X_l2)\n",
    "\n",
    "pred1 = tf.matmul(rel, w1)\n",
    "\n",
    "pred2 = tf.add(pred1,b1)\n",
    "\n",
    "sigmoid_pred = tf.sigmoid(pred2)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(targets = y3,logits = pred2, pos_weight= 1), name='cost')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, name='optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_generator(\n",
    "    myGenerator_tr, (tf.int32, tf.int32, tf.string, tf.float32, tf.string, tf.int32), (tf.TensorShape([]), tf.TensorShape([None]),tf.TensorShape([None]),tf.TensorShape([None,14]), tf.TensorShape([3]), tf.TensorShape([])))\n",
    "\n",
    "ds_train = ds_train.map(map_func1, num_parallel_calls=10)\n",
    "\n",
    "train_dataset = ds_train.shuffle(buffer_size=10)\n",
    "train_dataset = ds_train.repeat()\n",
    "\n",
    "ds_train = ds_train.padded_batch(2, padded_shapes=([],[None],[None],[None,14],[None], [], [None], []))\n",
    "\n",
    "ds_train = ds_train.map(map_func2, num_parallel_calls=10)\n",
    "\n",
    "train_next_element = ds_train.make_one_shot_iterator().get_next()\n",
    "\n",
    "ds_test = tf.data.Dataset.from_generator(\n",
    "    myGenerator_test, (tf.int32, tf.int32, tf.string, tf.float32, tf.string, tf.int32), (tf.TensorShape([]), tf.TensorShape([None]),tf.TensorShape([None]),tf.TensorShape([None,14]), tf.TensorShape([3]), tf.TensorShape([])))\n",
    "\n",
    "ds_test = ds_test.map(map_func1, num_parallel_calls=10)\n",
    "\n",
    "ds_test = ds_test.padded_batch(2, padded_shapes=([],[None],[None],[None,14],[None], [], [None], []))\n",
    "\n",
    "ds_test = ds_test.map(map_func2, num_parallel_calls=10)\n",
    "\n",
    "test_iterator = ds_test.make_initializable_iterator()\n",
    "test_next_element = test_iterator.get_next()\n",
    "\n",
    "train_dataset = ds_train.prefetch(5)\n",
    "test_dataset = ds_test.prefetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.99980026]\n",
      " [0.99950886]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.9996393]\n",
      " [0.9993036]]\n",
      "[[1.]]\n",
      "[[0.994532]]\n",
      "Test AUC:[0.15]\n",
      "1\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.98509926]\n",
      " [0.9957248 ]]\n",
      "[[0.]]\n",
      "[[0.9883797]]\n",
      "[[0.]]\n",
      "[[0.9753067]]\n",
      "[[0.]]\n",
      "[[0.95138985]]\n",
      "[[0.]]\n",
      "[[0.938113]]\n",
      "[[0.]]\n",
      "[[0.8882503]]\n",
      "[[0.]]\n",
      "[[0.7448517]]\n",
      "[[0.]]\n",
      "[[0.1700356]]\n",
      "[[0.]]\n",
      "[[0.32377034]]\n",
      "[[0.]]\n",
      "[[0.3610526]]\n",
      "[[0.]]\n",
      "[[0.25793266]]\n",
      "[[0.]]\n",
      "[[0.07666402]]\n",
      "2\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04267583]\n",
      " [0.01460495]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03796801]\n",
      " [0.0066658 ]]\n",
      "[[0.]]\n",
      "[[0.01393086]]\n",
      "[[0.]]\n",
      "[[0.00583404]]\n",
      "3\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.0079277 ]\n",
      " [0.02778624]]\n",
      "[[0.]]\n",
      "[[0.0005376]]\n",
      "[[0.]]\n",
      "[[0.00366715]]\n",
      "4\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00054498]\n",
      " [0.00357448]]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.00233402]\n",
      " [0.00358052]]\n",
      "[[0.]]\n",
      "[[0.0002302]]\n",
      "[[0.]]\n",
      "[[0.00033845]]\n",
      "[[1.]]\n",
      "[[0.00286164]]\n",
      "5\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00256737]\n",
      " [0.00066697]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00414534]\n",
      " [0.00352834]]\n",
      "6\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00604642]\n",
      " [0.00264507]]\n",
      "[[0.]]\n",
      "[[0.00608156]]\n",
      "7\n",
      "[[1.]\n",
      " [0.]]\n",
      "[[0.00011032]\n",
      " [0.00047556]]\n",
      "[[0.]]\n",
      "[[0.00622943]]\n",
      "[[1.]]\n",
      "[[0.0029081]]\n",
      "8\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00086315]\n",
      " [0.00820212]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01279738]\n",
      " [0.01165281]]\n",
      "9\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00903748]\n",
      " [0.00614474]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02239197]\n",
      " [0.03255372]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02496622]\n",
      " [0.00394791]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03398265]\n",
      " [0.03188244]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.0319274 ]\n",
      " [0.02430013]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04633473]\n",
      " [0.00371755]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02921427]\n",
      " [0.02639895]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00548861]\n",
      " [0.03215335]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03150251]\n",
      " [0.02435652]]\n",
      "[[0.]]\n",
      "[[0.03961999]]\n",
      "[[0.]]\n",
      "[[0.02846295]]\n",
      "[[0.]]\n",
      "[[0.0290395]]\n",
      "[[0.]]\n",
      "[[0.00627736]]\n",
      "[[0.]]\n",
      "[[0.04941145]]\n",
      "[[0.]]\n",
      "[[0.03241931]]\n",
      "[[0.]]\n",
      "[[0.01791448]]\n",
      "[[0.]]\n",
      "[[0.00694653]]\n",
      "[[0.]]\n",
      "[[0.03491116]]\n",
      "[[1.]]\n",
      "[[0.00136092]]\n",
      "10\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.08260071]\n",
      " [0.00693195]]\n",
      "[[0.]]\n",
      "[[0.03053335]]\n",
      "[[0.]]\n",
      "[[0.0397932]]\n",
      "[[0.]]\n",
      "[[0.03975878]]\n",
      "Test AUC:[0.15, 0.75]\n",
      "11\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.08896245]\n",
      " [0.14017095]]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.11839806]\n",
      " [0.07316847]]\n",
      "[[0.]]\n",
      "[[0.09725706]]\n",
      "[[0.]]\n",
      "[[0.07133074]]\n",
      "[[0.]]\n",
      "[[0.11100157]]\n",
      "[[1.]]\n",
      "[[0.5114185]]\n",
      "12\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07315955]\n",
      " [0.13801034]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.13718815]\n",
      " [0.05735517]]\n",
      "[[0.]]\n",
      "[[0.05472171]]\n",
      "13\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.08101372]\n",
      " [0.18803693]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.08321672]\n",
      " [0.09746499]]\n",
      "[[0.]]\n",
      "[[0.05802114]]\n",
      "14\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05455973]\n",
      " [0.07995554]]\n",
      "[[0.]]\n",
      "[[0.05753252]]\n",
      "15\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.12126017]\n",
      " [0.05580324]]\n",
      "[[0.]]\n",
      "[[0.89453703]]\n",
      "[[0.]]\n",
      "[[0.14646395]]\n",
      "[[0.]]\n",
      "[[0.09709102]]\n",
      "[[0.]]\n",
      "[[0.0883102]]\n",
      "[[0.]]\n",
      "[[0.0616792]]\n",
      "[[0.]]\n",
      "[[0.0530052]]\n",
      "[[1.]]\n",
      "[[0.03553786]]\n",
      "16\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03292859]\n",
      " [0.04287756]]\n",
      "[[0.]]\n",
      "[[0.14150698]]\n",
      "17\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03261387]\n",
      " [0.03041961]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04330785]\n",
      " [0.0284958 ]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04110779]\n",
      " [0.03925258]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02279275]\n",
      " [0.10831008]]\n",
      "[[0.]]\n",
      "[[0.02039986]]\n",
      "[[0.]]\n",
      "[[0.02339996]]\n",
      "[[0.]]\n",
      "[[0.02999797]]\n",
      "18\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05038292]\n",
      " [0.04696598]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04011777]\n",
      " [0.06315875]]\n",
      "19\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03952835]\n",
      " [0.0778193 ]]\n",
      "[[0.]]\n",
      "[[0.03056535]]\n",
      "20\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07127136]\n",
      " [0.01037716]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05391472]\n",
      " [0.04781863]]\n",
      "[[0.]]\n",
      "[[0.04580635]]\n",
      "[[0.]]\n",
      "[[0.02687657]]\n",
      "[[0.]]\n",
      "[[0.01655982]]\n",
      "[[0.]]\n",
      "[[0.02834097]]\n",
      "[[0.]]\n",
      "[[0.01274049]]\n",
      "[[0.]]\n",
      "[[0.02793458]]\n",
      "[[0.]]\n",
      "[[0.02841592]]\n",
      "[[0.]]\n",
      "[[0.02213435]]\n",
      "Test AUC:[0.15, 0.75, 0.7333333333333334]\n",
      "21\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02245263]\n",
      " [0.02345515]]\n",
      "[[0.]]\n",
      "[[0.00504296]]\n",
      "[[0.]]\n",
      "[[0.02415205]]\n",
      "[[0.]]\n",
      "[[0.02239862]]\n",
      "[[0.]]\n",
      "[[0.01907458]]\n",
      "[[0.]]\n",
      "[[0.02772575]]\n",
      "[[0.]]\n",
      "[[0.01935996]]\n",
      "[[0.]]\n",
      "[[0.00460153]]\n",
      "[[0.]]\n",
      "[[0.00334369]]\n",
      "[[0.]]\n",
      "[[0.01974153]]\n",
      "[[0.]]\n",
      "[[0.02319185]]\n",
      "[[0.]]\n",
      "[[0.0179763]]\n",
      "[[0.]]\n",
      "[[0.01841871]]\n",
      "[[0.]]\n",
      "[[0.00446841]]\n",
      "[[0.]]\n",
      "[[0.00622724]]\n",
      "[[0.]]\n",
      "[[0.00778343]]\n",
      "[[0.]]\n",
      "[[0.00282856]]\n",
      "[[0.]]\n",
      "[[0.01690806]]\n",
      "[[0.]]\n",
      "[[0.01630805]]\n",
      "[[0.]]\n",
      "[[0.00345626]]\n",
      "[[0.]]\n",
      "[[0.01722872]]\n",
      "[[0.]]\n",
      "[[0.01280275]]\n",
      "[[0.]]\n",
      "[[0.00259955]]\n",
      "[[0.]]\n",
      "[[0.0030638]]\n",
      "[[1.]]\n",
      "[[0.01235041]]\n",
      "22\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02688477]\n",
      " [0.03362662]]\n",
      "[[0.]]\n",
      "[[0.02771891]]\n",
      "[[0.]]\n",
      "[[0.04177806]]\n",
      "23\n",
      "[[1.]\n",
      " [0.]]\n",
      "[[0.1185883]\n",
      " [0.0210174]]\n",
      "24\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.00449955]\n",
      " [0.00724697]]\n",
      "[[1.]]\n",
      "[[0.01654192]]\n",
      "25\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.11505436]\n",
      " [0.10611543]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.06980768]\n",
      " [0.1275958 ]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07599086]\n",
      " [0.1426179 ]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07352299]\n",
      " [0.16234772]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.0768723 ]\n",
      " [0.13974045]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04517021]\n",
      " [0.16093479]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.09640065]\n",
      " [0.04820455]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.13748267]\n",
      " [0.12325356]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.1100862 ]\n",
      " [0.22030629]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.11962625]\n",
      " [0.19268355]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.09921727]\n",
      " [0.12573078]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05119733]\n",
      " [0.12083135]]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.07299133]\n",
      " [0.02218437]]\n",
      "[[0.]]\n",
      "[[0.0676014]]\n",
      "[[0.]]\n",
      "[[0.00900421]]\n",
      "[[0.]]\n",
      "[[0.1129502]]\n",
      "[[0.]]\n",
      "[[0.00991216]]\n",
      "[[0.]]\n",
      "[[0.11607744]]\n",
      "[[0.]]\n",
      "[[0.08465482]]\n",
      "26\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01628431]\n",
      " [0.03639077]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07996716]\n",
      " [0.07505589]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.07180256]\n",
      " [0.1000788 ]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.06389952]\n",
      " [0.01152381]]\n",
      "[[0.]]\n",
      "[[0.01126531]]\n",
      "[[0.]]\n",
      "[[0.09063292]]\n",
      "27\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.09752017]\n",
      " [0.05606712]]\n",
      "[[0.]]\n",
      "[[0.05363001]]\n",
      "28\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.04903295]\n",
      " [0.01287782]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05098781]\n",
      " [0.04734591]]\n",
      "[[0.]]\n",
      "[[0.01188609]]\n",
      "[[0.]]\n",
      "[[0.04824032]]\n",
      "[[0.]]\n",
      "[[0.03591141]]\n",
      "[[0.]]\n",
      "[[0.01044346]]\n",
      "[[0.]]\n",
      "[[0.03111007]]\n",
      "[[0.]]\n",
      "[[0.01399937]]\n",
      "[[0.]]\n",
      "[[0.00801074]]\n",
      "[[0.]]\n",
      "[[0.02880701]]\n",
      "[[0.]]\n",
      "[[0.02642195]]\n",
      "[[0.]]\n",
      "[[0.01886943]]\n",
      "[[0.]]\n",
      "[[0.02864869]]\n",
      "[[0.]]\n",
      "[[0.00829089]]\n",
      "[[1.]]\n",
      "[[0.5837234]]\n",
      "29\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.01027376]\n",
      " [0.02991509]]\n",
      "[[0.]]\n",
      "[[0.02590899]]\n",
      "30\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02942593]\n",
      " [0.04730338]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.0205135 ]\n",
      " [0.04687427]]\n",
      "[[0.]]\n",
      "[[0.03479737]]\n",
      "Test AUC:[0.15, 0.75, 0.7333333333333334, 0.7666666666666667]\n",
      "31\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.11222567]\n",
      " [0.02217969]]\n",
      "[[0.]]\n",
      "[[0.03986885]]\n",
      "[[0.]]\n",
      "[[0.03220766]]\n",
      "[[0.]]\n",
      "[[0.03308826]]\n",
      "[[0.]]\n",
      "[[0.04477579]]\n",
      "[[0.]]\n",
      "[[0.01528558]]\n",
      "[[0.]]\n",
      "[[0.04267035]]\n",
      "32\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03919436]\n",
      " [0.06358152]]\n",
      "[[0.]]\n",
      "[[0.03757974]]\n",
      "[[0.]]\n",
      "[[0.01104582]]\n",
      "[[0.]]\n",
      "[[0.03211103]]\n",
      "[[0.]]\n",
      "[[0.10244537]]\n",
      "[[1.]]\n",
      "[[0.03085178]]\n",
      "33\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03721391]\n",
      " [0.03458505]]\n",
      "34\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.05131552]\n",
      " [0.0370772 ]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03651921]\n",
      " [0.03655244]]\n",
      "[[0.]]\n",
      "[[0.04246772]]\n",
      "[[0.]]\n",
      "[[0.08849901]]\n",
      "[[0.]]\n",
      "[[0.08126591]]\n",
      "[[0.]]\n",
      "[[0.0789779]]\n",
      "[[0.]]\n",
      "[[0.09916894]]\n",
      "[[0.]]\n",
      "[[0.05396909]]\n",
      "[[0.]]\n",
      "[[0.01751583]]\n",
      "[[0.]]\n",
      "[[0.05465043]]\n",
      "[[0.]]\n",
      "[[0.07537152]]\n",
      "[[0.]]\n",
      "[[0.06266743]]\n",
      "[[0.]]\n",
      "[[0.01484277]]\n",
      "[[0.]]\n",
      "[[0.06191126]]\n",
      "[[0.]]\n",
      "[[0.04095264]]\n",
      "[[0.]]\n",
      "[[0.01304379]]\n",
      "[[0.]]\n",
      "[[0.01227399]]\n",
      "[[0.]]\n",
      "[[0.04544165]]\n",
      "[[0.]]\n",
      "[[0.05425779]]\n",
      "[[0.]]\n",
      "[[0.05609706]]\n",
      "[[0.]]\n",
      "[[0.06053966]]\n",
      "[[0.]]\n",
      "[[0.04018399]]\n",
      "[[0.]]\n",
      "[[0.04574715]]\n",
      "[[0.]]\n",
      "[[0.04353457]]\n",
      "[[0.]]\n",
      "[[0.04034308]]\n",
      "[[0.]]\n",
      "[[0.08835975]]\n",
      "[[0.]]\n",
      "[[0.04388404]]\n",
      "[[0.]]\n",
      "[[0.03297612]]\n",
      "[[0.]]\n",
      "[[0.00890121]]\n",
      "[[0.]]\n",
      "[[0.03246329]]\n",
      "[[0.]]\n",
      "[[0.03088025]]\n",
      "[[0.]]\n",
      "[[0.01834774]]\n",
      "[[0.]]\n",
      "[[0.04999728]]\n",
      "[[0.]]\n",
      "[[0.01527902]]\n",
      "[[0.]]\n",
      "[[0.0419314]]\n",
      "[[0.]]\n",
      "[[0.02047094]]\n",
      "[[0.]]\n",
      "[[0.02403599]]\n",
      "[[0.]]\n",
      "[[0.02460274]]\n",
      "[[0.]]\n",
      "[[0.04121315]]\n",
      "[[0.]]\n",
      "[[0.04426811]]\n",
      "[[1.]]\n",
      "[[0.21090376]]\n",
      "35\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.00488645]\n",
      " [0.01545054]]\n",
      "[[0.]]\n",
      "[[0.01924073]]\n",
      "[[0.]]\n",
      "[[0.00671167]]\n",
      "[[0.]]\n",
      "[[0.00706762]]\n",
      "[[0.]]\n",
      "[[0.0082162]]\n",
      "[[0.]]\n",
      "[[0.02707122]]\n",
      "[[0.]]\n",
      "[[0.02833332]]\n",
      "[[0.]]\n",
      "[[0.02686425]]\n",
      "[[0.]]\n",
      "[[0.02685324]]\n",
      "[[0.]]\n",
      "[[0.03255926]]\n",
      "[[0.]]\n",
      "[[0.01995011]]\n",
      "[[0.]]\n",
      "[[0.0207186]]\n",
      "[[0.]]\n",
      "[[0.03134083]]\n",
      "[[0.]]\n",
      "[[0.0313084]]\n",
      "[[0.]]\n",
      "[[0.02838409]]\n",
      "[[0.]]\n",
      "[[0.02884535]]\n",
      "[[0.]]\n",
      "[[0.03069551]]\n",
      "[[0.]]\n",
      "[[0.02850652]]\n",
      "[[0.]]\n",
      "[[0.0294055]]\n",
      "[[0.]]\n",
      "[[0.02741863]]\n",
      "[[0.]]\n",
      "[[0.02706024]]\n",
      "[[0.]]\n",
      "[[0.025969]]\n",
      "[[0.]]\n",
      "[[0.02988676]]\n",
      "[[0.]]\n",
      "[[0.02904221]]\n",
      "[[0.]]\n",
      "[[0.02319919]]\n",
      "[[0.]]\n",
      "[[0.04145131]]\n",
      "[[0.]]\n",
      "[[0.02318309]]\n",
      "36\n",
      "[[1.]\n",
      " [0.]]\n",
      "[[0.9926233 ]\n",
      " [0.09370208]]\n",
      "[[0.]]\n",
      "[[0.04375865]]\n",
      "37\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02097856]\n",
      " [0.02252439]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01532059]\n",
      " [0.01833257]]\n",
      "[[1.]]\n",
      "[[0.9999869]]\n",
      "38\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.03904019]\n",
      " [0.9999733 ]]\n",
      "[[0.]]\n",
      "[[0.02335805]]\n",
      "[[0.]]\n",
      "[[0.0279431]]\n",
      "[[1.]]\n",
      "[[0.9571119]]\n",
      "39\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.0176094 ]\n",
      " [0.01962951]]\n",
      "[[0.]]\n",
      "[[0.02564152]]\n",
      "40\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01728508]\n",
      " [0.0594808 ]]\n",
      "[[0.]]\n",
      "[[0.01757604]]\n",
      "[[0.]]\n",
      "[[0.03412937]]\n",
      "[[0.]]\n",
      "[[0.01663455]]\n",
      "Test AUC:[0.15, 0.75, 0.7333333333333334, 0.7666666666666667, 0.8333333333333334]\n",
      "41\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.02870068]\n",
      " [0.01191164]]\n",
      "42\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01985607]\n",
      " [0.07958392]]\n",
      "[[0.]]\n",
      "[[0.01647571]]\n",
      "[[0.]]\n",
      "[[0.01981452]]\n",
      "[[0.]]\n",
      "[[0.02022251]]\n",
      "43\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02073535]\n",
      " [0.01429597]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01756436]\n",
      " [0.18558322]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01631908]\n",
      " [0.02954282]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02954556]\n",
      " [0.01579869]]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.01527992]\n",
      " [0.00786246]]\n",
      "[[0.]]\n",
      "[[0.01796264]]\n",
      "[[0.]]\n",
      "[[0.01517664]]\n",
      "[[0.]]\n",
      "[[0.02081169]]\n",
      "[[0.]]\n",
      "[[0.02072974]]\n",
      "[[0.]]\n",
      "[[0.01897284]]\n",
      "[[0.]]\n",
      "[[0.02802208]]\n",
      "[[0.]]\n",
      "[[0.16086459]]\n",
      "[[0.]]\n",
      "[[0.02333867]]\n",
      "[[0.]]\n",
      "[[0.03187153]]\n",
      "[[0.]]\n",
      "[[0.0188075]]\n",
      "[[1.]]\n",
      "[[0.9527307]]\n",
      "44\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02237576]\n",
      " [0.0308453 ]]\n",
      "[[0.]]\n",
      "[[0.0209784]]\n",
      "[[0.]]\n",
      "[[0.02697146]]\n",
      "[[0.]]\n",
      "[[0.10530857]]\n",
      "[[0.]]\n",
      "[[0.02271354]]\n",
      "[[0.]]\n",
      "[[0.08160009]]\n",
      "[[0.]]\n",
      "[[0.01947004]]\n",
      "[[0.]]\n",
      "[[0.01846484]]\n",
      "[[0.]]\n",
      "[[0.01765563]]\n",
      "45\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02919166]\n",
      " [0.01988572]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.02542847]\n",
      " [0.0182994 ]]\n",
      "[[0.]]\n",
      "[[0.01639931]]\n",
      "46\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.01688071]\n",
      " [0.02222694]]\n",
      "[[1.]\n",
      " [0.]]\n",
      "[[0.02964971]\n",
      " [0.01744794]]\n",
      "[[0.]]\n",
      "[[0.01666077]]\n",
      "[[0.]]\n",
      "[[0.02281776]]\n",
      "[[0.]]\n",
      "[[0.01830708]]\n",
      "[[0.]]\n",
      "[[0.01725114]]\n",
      "[[0.]]\n",
      "[[0.02771]]\n",
      "[[1.]]\n",
      "[[0.02558167]]\n",
      "47\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.0208241 ]\n",
      " [0.02602589]]\n",
      "[[0.]]\n",
      "[[0.02156918]]\n",
      "48\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.02564084]\n",
      " [0.03451364]]\n",
      "49\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.03569396]\n",
      " [0.04618388]]\n",
      "[[0.]]\n",
      "[[0.16248539]]\n",
      "[[0.]]\n",
      "[[0.52211154]]\n",
      "[[0.]]\n",
      "[[0.33970568]]\n",
      "[[0.]]\n",
      "[[0.03870386]]\n",
      "[[0.]]\n",
      "[[0.03948471]]\n",
      "[[0.]]\n",
      "[[0.04481831]]\n",
      "[[0.]]\n",
      "[[0.03979642]]\n",
      "[[0.]]\n",
      "[[0.04240824]]\n",
      "[[0.]]\n",
      "[[0.01850648]]\n",
      "[[0.]]\n",
      "[[0.0424449]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    AUC = []\n",
    "    for i in range(500):\n",
    "        print(i)\n",
    "#         print(sess.run(state))\n",
    "        train_value = sess.run(train_next_element)\n",
    "        #initializes hidden/cell states to zero at the beginning of each patient batch.\n",
    "        sess.run(tf.variables_initializer([state]))\n",
    "\n",
    "        for j in np.arange(np.shape(train_value[3])[0]):\n",
    "            #take the jth group's input and labels to feed into the LSTM.\n",
    "            batch_x, batch_y = train_value[3][j], train_value[6][j]\n",
    "\n",
    "            feed = {X: batch_x, y: batch_y}\n",
    "\n",
    "            #run the session.  (optimizer will update parameters).  State op will update the hidden state and cell state to the values at the end of the previous group.\n",
    "            result = sess.run([optimizer, state_op, y3, sigmoid_pred], feed_dict=feed)\n",
    "#             print(result[2])\n",
    "#             print(result[3])\n",
    "            \n",
    "        if (i+1)%100 == 0:\n",
    "            #save_path = saver.save(sess, \"../models/model5\" + str(m) + \".ckpt\")\n",
    "            #m +=1\n",
    "            #create arrays for the prediction outputs and labels.\n",
    "            preds = np.array([])\n",
    "            labs = np.array([])\n",
    "            #initialize the test iterator to start at the beginning\n",
    "            sess.run(test_iterator.initializer)\n",
    "            for i in np.arange(50):\n",
    "                try:\n",
    "                    test_value = sess.run(test_next_element)\n",
    "    #                 print(sess.run(state))\n",
    "                    sess.run(tf.variables_initializer([state]))\n",
    "    #                 print(sess.run(state))\n",
    "    #                 print(test_value[1])\n",
    "\n",
    "                    for k in np.arange(np.shape(test_value[3])[0]):\n",
    "                        #take the k'th group's input and labels to feed into the LSTM.\n",
    "                        batch_x, batch_y = test_value[3][k], test_value[6][k]\n",
    "\n",
    "                        feed = {X: batch_x, y: batch_y}\n",
    "\n",
    "                        result = sess.run([sigmoid_pred, y3, state_op], feed_dict=feed)\n",
    "                        #append the predictions and labels to the arrays\n",
    "                        preds = np.append(preds, result[0].flatten())\n",
    "                        labs = np.append(labs, result[1].flatten())\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            #Compute and print the area under receiver operator curve for predictions and labels\n",
    "            AUC.append(roc_auc_score(labs, preds))\n",
    "            print('Test AUC:' + str(AUC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
